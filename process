Launch & connect to EC2 (t2.medium or higher recommended, at least 16 GB storage).

Install Ollama and pull a model.

Run a test chat with the model locally.

Set up Flask API to connect the model with your HTML UI.

#command
sudo yum update -y
sudo yum install -y curl git
curl -fsSL https://ollama.com/install.sh | sh         #Install Ollama
ollama --version
ollama pull llama3.2:1b
sudo yum install -y python3 python3-pip
pip3 install flask flask-cors
nano app.py
python3 app.py

structure
/home/ec2-user/ai-chatbot/
│
├── app.py                  # Your main Flask backend code
│
├── templates/              # HTML files for Flask (UI)
│   └── index.html

in ai-chatbot durectory run python3 app.py
